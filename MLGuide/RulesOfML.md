## 머신러닝의 규칙
- 머신러닝 관련 권장사항을 참고할 수 있도록 돕는 자료

## 용어
- 아래와 같은 용어가 반복적으로 사용됨 
  - 인스턴스:예측하려는 대상물을 의미/예를 들어 웹페이지를 '고양이와 관련됨' 혹은 '고양이와 무관함'으로 분류하는 경우 이 웹페이지가 인스턴스가 될 수 있음 
  - 라벨:예측 작업에 관한 답으로서, 머신러닝 시스템이 도출하거나 학습 데이터에서 제공된 정답임/예를 들어 웹페이지에 관한 라벨은 '고양이와 관련됨'일 수 있음 
  - 특성:예측 작업에 사용되는 인스턴스의 속성임/예를 들어 웹페이지는 '고양이라는 단어를 포함'한다는 특성을 가짐
  - 특성 열:서로 관련된 특성의 집합임/예를 들어, 사용자가 거주할 수 있는 모든 국가의 집합이 있음
    - 하나의 예는 특성 열에 하나 이상의 특성을 가질 수 있음/다른 시스템에서는 네임스페이스라고도 하고 필드라고도 지칭하는 경우가 있음
  - 예시:인스턴스(특성 포함)및 라벨을 함께 지칭함
  - 모델:예측 작업의 통계적 표현임/예시를 사용하여 모델을 학습한 후 그 모델을 사용하여 예측함
  - 측정항목:내가 관심이 있는 수치임/직접 최적화될 수도 있고, 그렇지 않을 수도 있음
  - 목표:알고리즘에서 최적화하려는 측정항목임
  - 파이프라인:머신러닝 알고리즘의 기반을 이루는 인프라/프런트 엔드에서 데이터를 수집하고, 데이터를 학습 데이터 파일에 넣어, 하나 이상의 모델을 학습함, 모델은 프로덕션 환경으로 내보내는 과정이 포함됨 
  - 클릭률:웹페이지 방문자가 광고의 링크를 클릭하는 비율임

## 개요
- 기본적인 접근법
  - 1.파이프라인에 처음부터 끝까지 빈틈이 없는지 확인함
  - 2.합리적인 목표부터 시작함
  - 3.상식선에서 단순한 방식으로 특성을 추가함
  - 4.파이프라인에 빈틈이 없는지 확인함
- 단순한 방식으로 더 이상 진전을 기대할 수 없는 경우에만 이외에 다른 접근법을 모색해야함/복잡성이 더해지면 개발이 느려짐
- 단순한 방식으로 부족하다면 지금부터 배울 머신러닝 기법에 도전해야함/3단계 머신러닝 프로젝트
  - 1부에서는 머신러닝 시스템을 구축하기에 적절한 시점을 판단하는데 도움을 줌
  - 2부에서는 첫 번째 파이프라인을 구축하는 방법을 설명함
  - 3부에서는 파이프라인에 새 특성을 추가해가며 출시와 반복을 거듭하고, 모델 및 학습-서빙 격차를 평가하는 방법을 설명함
  - 4부에서는 개선이 한계에 부딪치면 무엇을 해야 하는지 설명함
  
## 시작전
- 규칙 #1:머신러닝 없이 제품을 출시하는 것을 두려워하지 말라.
  - 머신러닝은 우선 데이터가 필요함/다른 문제로부터 데이터를 가져와서 모델을 약간 수정하여 새 제품에 적용하는 방법은 이론적으로는 가능하지만 기초적인 휴리스틱보다도 성능이 떨어질 수도 있음
  - 머신러닝이 제품에 절대적으로 필요한 기능이 아니라면 데이터를 충분히 수집하기 전까지는 사용하지 마라
- 규칙 #2:가장 먼저 측정항목을 설계하고 구현하라.
  - 머신러닝의 기능과 역할을 공식화하기 전에 현재 시스템의 상황을 최대한 자세히 추적해야 함
    - 1.시스템 사용자로부터 미리 사용 권한을 받는 것이 여러모로 수월함
    - 2.향후 발생할 것으로 예상하는 문제점이 있다면 지금부터 이전 데이터를 수집해 두는 편이 좋음
    - 3.측정항목 계측을 염두에 두고 시스템을 설계한다면 나중에 작업이 편해짐/측정항목을 계측하기 위해 로그에서 문자열을 일일이 grep으로 추출할 필요가 없어짐 
    - 4.무엇이 변하고 무엇이 그대로인지 알게 됨
  - 측정항목을 적극적으로 수집할수록 시스템을 전반적으로 파악하기가 쉬워짐 
- 규칙 #3:휴리스틱이 복잡하다면 머신러닝을 선택하라.
  - 휴리스틱이 복잡하면 유지보수가 불가능함/데이터가 확보되었고 달성하려는 목표가 가시화되었다면 머신러닝으로 이행할 수 있음
  - 접근 방식에 대해 끊임없는 업데이트가 필요함/머신러닝 모델이 업데이트 및 유지보수가 더 쉬움

## ML 1단계:첫 번째 파이프라인
- 시스템 인프라를 갖추는 데 집중하여라/파이프라인을 신뢰할 수 있어야 현상을 제대로 파악할 수 있음
- 규칙 #4:최초 모델은 단순하게 유지하고 인프라를 제대로 갖춰라.
  - 첫 번째 모델은 제품 개선에 가장 크게 기여하게 되므로 처음부터 화려한 기능을 갖출 필요는 없음
  - 머신러닝 시스템을 제공하기 전에 다음과 같은 사항을 결정해야함
    - 학습 알고리즘에 예시를 제공할 방법
    - 시스템의 '양호함'과 '불량함'을 판단할 최초 기준
    - 모델을 애플리케이션에 통합할 방법
      - 모델을 실시간으로 적용할 수도 있고, 오프라인에서 예시를 가지고 모델을 미리 연산하여 결과를 테이블에 저장할 수도 있음
      - 예를 들어 웹페이지는 미리 분류하여 테이블에 결과를 저장하는 한편, 채팅 메시지는 실시간으로 분류할 수 있음
  - 단순한 특성 선택 시 다음과 같은 과제를 달성하기가 쉬워짐
    - 특성이 학습 알고리즘에 정확히 도달함
    - 모델이 합리적인 가중치를 학습함
    - 특성이 서버의 모델에 정확히 도달함
      - 위와 같은 3가지 과제를 달성했다면 준비는 끝/이 단순한 모델에서 기준 측정항목과 기준 동작을 얻어 더 복잡한 모델을 테스트하는 데 사용할 수 있음
- 규칙 #5:머신러닝과 별도로 인프라를 테스트하라.
  - 인프라는 테스트할 수 있어야 하며, 시스템의 학습 부분을 캡슐화해야 모든 관련 부분을 테스트할 수 있음
    - 1.알고리즘에 데이터를 넣는 기능을 테스트함/채워져야 하는 특성 열이 채워지는지 확인함/개인정보를 보호하는 범위 내에서 학습 알고리즘의 입력값을 직접 조사함/가능한 경우 파이프라인의 통계를 다른 곳에서 데이터를 처리해 나온 통계와 서로 비교함
    - 2.모델을 학습 알고리즘에서 꺼내는 기능을 테스트함/학습 환경의 모델이 주는 점수가 서빙 환경의 모델과 동일한지 확인함
  - 머신러닝에는 예측 불가능성이 있으므로 학습 및 서빙 시 예시를 생성하는 코드를 테스트할 준비를 하고, 서빙 중에 고정 모델을 로드하여 사용할 수 있을지 확인함/데이터를 이해하는 것이 중요함 
- 규칙 #6:파이프라인을 복사할 때는 데이터 누락에 주의하라.
  - 기존 파이프라인을 복사하여 파이프라인을 만들었는데, 새 파이프라인에 필요한 데이터가 이전 파이프라인에서 누락되는 경우가 종종 있음
  - 사용자가 조회한 데이터만 기록하는 패턴이 있기도 함 
- 규칙 #7:휴리스틱을 특성으로 변환하거나 외부에서 처리하라.
  - 머신러닝으로 해결하려는 문제들은 일반적으로 새로 등장한 문제는 아님/어떠한 문제든 이를 해결하는 기존 시스템이 있음
  - 수많은 규칙과 휴리스틱이 이미 존재하고 있음/이러한 휴리스틱을 머신러닝과 조합하면 돌파구를 마련할 수 있음 
  - 기존 휴리스틱을 철저히 분석해야 하는 두 가지 이유는 다음과 같음
    - 1.머신러닝 시스템으로 더욱 매끄럽게 전환할 수 있음
    - 2.이러한 규칙은 시스템에 대해 버리기 아까운 직관을 풍부하게 담고 있음
  - 네 가지 방법으로 기존 휴리스틱을 활용할 수 있음
    - 1.휴리스틱을 사용하여 전처리함/품질이 뛰어난 특성인 경우에는 고려해볼 만함/이진 분류 작업시
    - 2.특성을 만듬/휴리스틱에서 직접 특성을 만들면 좋음/예를 들어 휴리스틱을 사용하여 쿼리 결과의 관련성 점수를 계산하는 경우 이 점수를 특성값으로 포함할 수 있음/이후에 값을 불연속 값의 유한집합 중 하나로 변환하거나 값을 다른 특성과 합하는 등의 머신러닝 기법을 사용하여 값을 조정할 수 있지만 처음에는 휴리스틱으로 산출되는 값을 그대로 사용해도 됨 
    - 3.휴리스틱의 원시 입력값을 마이닝함/앱에 대해 설치 횟수,텍스트 문자 수,요일을 결합하는 휴리스틱이 있다면 이러한 값을 따로따로 가져와서 학습에 별도로 제공하는 것이 좋음 
    - 4.라벨을 수정함/휴리스틱이 현재 라벨에 포함되지 않는 정보를 포착한다고 생각될 때 이 방법을 사용할 수 있음
  - ML시스템에서 휴리스틱을 사용하는 경우 복잡성이 더해진다는 점에 유의하여라/새로운 머신러닝 알고리즘에 기존 휴리스틱을 사용하면 전환 과정이 원할해질 수 있지만, 더 간단한 방법으로 같은 효과를 낼 수는 없을지 고민해야함
 
## 모니터링
- 일반적인 권장사항은 알림을 깔끔하게 유지하는 것임/알림에 실질적인 정보를 기재하고 대시보드 페이지를 준비해야함
- 규칙 #8:시스템의 갱신 요구사항을 파악하라.
  - 모델이 시간이 지남에 따라 성능이 얼마나 떨어지는지 파악해봐라/이 정보는 모니터링의 우선순위를 판단하는 데 도움이 됨 
  - 하루 동안 모델을 업데이트하지 않으면 제품의 품질이 심각하게 저하되는 경우 모델을 지속적으로 모니터링 해야함
- 규칙 #9:모델을 내보내기 전에 문제를 탐지하라.
  - 모델을 서빙 환경으로 내보내는 단계가 있는데, 내보낸 모델에 문제가 있는 경우 사용자가 곧바로 알아차리게 됨 
  - 모델을 내보내기 전에 상태 확인을 수행하여라/홀드아웃 데이터에 관한 모델의 성능이 적절한지 확인해야 함
  - 데이터의 신빙성이 의심되는 경우 모델을 내보내지 말아라/계속해서 내보낼 경우 대부분 AUC(ROC곡선 아래 영역)를 확인한 후에 내보냄
  - 모델을 제때 내보내지 못하는 이슈는 이메일 알림으로 해결 할 수 있지만, 문제가 있는 모델을 사용자에게 제공하면 사태가 커짐/늦더라도 최대한 만전을 기하는 것이 좋음
- 규칙 #10:조용한 실패에 주의하라.
  - 조인 대상이 되는 특정 테이블이 더 이상 업데이트되지 않는다고 가정해 봄/이 테이블에 따라 머신러닝 시스템을 조정하면 겉보기에는 특별한 문제가 없더라도 실제로는 성능이 점점 떨어짐
  - 몇 달 동안 그대로였던 테이블을 찾아내서 갱신하는 것만으로도 놀라운 성능 개선 효과를 거둘 수 있음 
  - 구현 변경으로 인해 특성의 포함 범위가 바뀌기도 함
  - 예를 들어 특성 열이 입력된 예시의 비율이 90%에서 60%로 급락할 수 있음/Play의 경우 6개월 동안 그대로였던 테이블을 갱신했더니 설치율이 2%나 상승함 
    - 데이터의 통계를 추적하고 경우에 따라 직접 조사하면 이러한 유형의 실패를 줄일 수 있음 
- 규칙 #11:특성 열에 소유자를 지정하고 문서화하라.
  - 시스템의 규모가 크고 특성 열이 많은 경우 각 특성 열을 누가 만들었고 누가 관리하는지를 알아야함
  - 이름만 봐도 의미를 알 수 있는 특성 열도 많긴 하지만 특성의 의미, 출처, 유용성을 자세히 기록해 두는 습관을 들이는 것이 좋음

## 첫 번째 목표
- 시스템에서 중요하다고 생각하는 측정항목이 아무리 많더라도 머신러닝 알고리즘에 필요한 목표, 알고리즘에서 최적화를 '시도'히는 수치는 일반적으로 단 하나임
- 목표와 측정항목을 잘 구분해야함/측정항목은 시스템에서 보고하는 모든 수치로서 중요할 수도, 그렇지 않을 수도 있음 
- 규칙 #12:어떤 목표를 직접 최적화할지 지나치게 고민하지 말라.
  - 모든 측정항목이 쉽게 증가할 수 있으므로, 다양한 측정항목 간에 균형을 맞추려고 지나치게 고민하지 말고 단순하게 생각하면 됨
  - 이 규칙에는 한도가 있음/목표와 시스템의 궁극적인 건전성을 혼동해서는 안됨
  - 직접 최적화하는 측정항목은 개선되지만 결국 출시에 실패하는 상황이 반복된다면 목표를 수정해야 할 수 있음
- 규칙 #13:단순하고 관찰 가능하며 추적 가능한 측정항목을 첫 번째 목표로 선택하라.
  - ML 목표는 측정하기 쉬우면서도 '진정한'목표를 반영해야함
  - 실제로는 '진정한'목표가 존재하지 않는 경우도 많음/따라서 단순한 ML 목표를 기준으로 학습하되, 또다른 로직(가급적 매우 단순하 로직)을 추가해 최종 순위를 결정할 수 있도록 '정책 레이어'를 상단에 두는 것이 좋음
  - 가장 모델링하기 쉬운 대상은 직접 관찰되고 시스템 동작과의 인과성을 추적할 수 있는 사용자 행동임
    - 순위 결정 대상 링크가 클릭되었는가?
    - 순위 결정 대상 개체가 다운로드되었는가?
    - 순위 결정 대상 개체가 전달되거나, 회신되거나, 이메일로 발송되었는가?
    - 순위 결정 대상 개체가 평가되었는가?
    - 표시 대상 개체가 스팸/음란물/불쾌감을 주는 콘텐츠로 신고되었는가?
  - 간접 효과는 처음에는 모델링하지 마라.
    - 사용자가 다음 날 방문했는가?
    - 사용자가 사이트를 얼마나 오래 방문했는가?
    - 일일 활성 사용자 수는 몇인가?
  - 간접 효과도 유용한 측정항목으로서 A/B테스트 및 출시 결정에 활용될 수 있음
  - 다음과 같은 의문을 해결하는데 머신러닝을 동원하지 마라.
    - 사용자가 제품에 만족하고 있는가?
    - 사용자 경험이 만족스러운가?
    - 제품이 사용자의 전반적인 삶의 질을 높여주는가?
    - 회사의 전반적인 건전성에 어떠한 영향을 줄 것인가?
  - 위 모두가 의문점이지만 측정하기란 매우 어려움/간접적인 기준으로 대신해라
  - 삶의 질이나 회사의 건전성과 관련해서는 머신러닝으로 도출된 목표를 판매할 제품 및 비즈니스 계획의 성격과 연결짓는 데 사람의 판단이 필수적임 
- 규칙 #14:해석 가능한 모델부터 시작하면 디버깅이 쉬워짐 
  - 선형 회귀, 로지스틱 회귀, 푸아송 회귀는 확률론 모델로부터 직접 유래한 것임
  - 각 예측은 확률 또는 기대값으로 해석할 수 있음/분류 정확성 또는 순위 결정 성능을 직접 최적화하려는 0-1 손실, 다양한 힌지 손실 등의 목표를 사용하는 모델보다 디버깅이 쉬워짐 
  - 예를 들어 학습 시스템의 확률이 병렬로 운용되거나 별도로 조사된 프로덕션 시스템의 확률과 차이가 난다면 이를 통해 문제점을 드러낼 수 있음
  - 예를 들어 선형, 로지스틱 또는 푸아송 회귀에서는 데이터 중에서 평균 예측 기대값이 평균 라벨(1모멘트 보정 또는 균등 보정)과 일치하는 부분집합이 존재함/이 사실은 정규화를 사용하지 않고 알고리즘이 수렴한다는 전제하에 항상 참이며, 일반적인 경우에는 근사적으로 참임
  - 각 예시에서 1 아니면 0인 특성이 있는 경우 해당 특성이 1인 예시 3개를 포함하는 집합이 보정됨/또한 어떤 특성이 모든 예시에서 1이라면 모든 예시를 포함하는 집합이 보정됨 
  - 단순 모델에서는 피드백 루프를 다루는 방법이 더 쉬움/이러한 확률적 예측을 근거로 결정을 내리는 경우가 많음
  - 그러나 어떠한 모델을 사용할지 선택할 때는 모델에 제공된 데이터의 확률보다 결정 그 자체가 더욱 중요함
- 규칙 #15:정책 레이어에서 스팸 필터링과 품질 순위화를 분리하라.
 - 품질 순위화에서는 정상적인 의도로 게시된 콘텐츠의 순위를 매기는 데 집중해야함 
 - 스팸 필터링은 완전히 다른 분야임/생성해야 하는 특성은 끊임없이 변화하게 마련임을 받아들여야함/때로는 시스템에 도입해야 하는 규칙이 분명함
 - 이러한 두 시스템의 출력을 일정 수준에서 통합해야함/주의할 점은 검색 결과의 스팸 필터링은 이메일 메시지의 스팸 필터링보다 더 과감해야 할 가능성이 높음/정규화를 사용하지 않고 알고리즘이 수렴한다는 전제하에 항상 참이며, 일반적인 경우에는 근사적으로 참임/스팸은 품질 분류용 학습 데이터에서 제외하는 것이 일반적인 관행임
 
## ML 2단계:특성 추출   
- 학습 시스템에 학습 데이터를 공급하고, 의미 있는 측정항목을 모두 계측하고, 서빙 인프라를 구축하는 것/단위 테스트와 시스템 테스트를 갖춘 정상적으로 작동하는 전체 시스템을 구축했을 시 이 단계로 옴
- 다양하고 알기 쉬운 특성들을 시스템에 집어넣음/최대한 많은 특성을 가져와서 직관적인 방식으로 결합하는 것이 관건임
- 모든 측정항목이 상승세를 보여야함/필요한 데이터를 모두 모아 학습 시스템의 역량을 극대화해야 할 시점임
- 규칙 #16:출시와 반복에 대비하라.
  - 지금 작업 중인 모델이 마지막 출시 버전이 될 것이라는 혹은 언젠가 끝나리라는 기대를 버려야함
  - 이번 출시에서 추가되는 복잡성으로 인해 이후 출시가 늦춰질 가능성이 있는지 고려해야함
  - 새 모델을 출시하는 기본적인 3가지 이유
    - 새로운 특성 도입
    - 정규화 조정 및 이전 특성을 새로운 방식으로 결합
    - 목표 조정
  - 예시에 공급되는 데이터를 조사하여 새로운 지표 또는 잘못된 기존 지표를 찾아낼 수 있음
  - 모델을 만들어 나가면서 특성 추가, 삭제 또는 재결합이 얼마나 용이한지를 생각해야 함
  - 파이프라인의 사본을 새로 만들고 정확성을 검증하기가 얼마나 쉬운지 생각해보라
  - 둘 이상의 사본을 동시에 실행하는 방법이 가능한지 생각해보라
  - 특정한 특성이 이번 파이프라인 버전에 포함될지 여부를 고민하지 마라/다음번 출시에 포함해도 됨
- 규칙 #17:학습된 특성이 아닌 직접 관찰 및 보고된 특성부터 시작하라.
  - 많은 함정을 피해갈 수 있음
  - 학습된 특성은 외부 시스템(비지도 클러스터링 시스템)또는 학습 시스템 자체(팩터링이 된 모델 또는 딥러닝)에 의해 생성된 특성임
  - 유용할 수 있지만 여러 가지 문제점을 가질 수 있으므로 최초 모델에는 포함해서는 안됨
  - 팩터링 모델과 심층 모델의 가장 큰 문제는 볼록하지 않다는 성질에 있음/따라서 최적의 해를 구하거나 근사할 수 있다는 보장이 없으며, 반복 시마다 서로 다른 국소적 최저점이 발견될 수 있음/이러한 변이는 시스템 변경에 따르는 영향이 의미를 갖는지 아니면 무작위적인지 판단하기 어렵게 만듬
  - 심층 특성이 없는 모델을 만들면 탁월한 기준 성능을 얻을 수 있음/이 기준이 확보된 이후에 특이하고 복잡한 접근법을 시도하여라
- 규칙 #18:여러 컨텍스트로 일반화되는 콘텐츠 특성을 살펴라.
  - 머신러닝 시스템은 더욱 거대한 시스템의 일부인 경우가 많음
  - 예를 들어 HOT 소식에 올라갈만한 게시물은 HOT 소식에 올라가기도 전에 많은 사람의 +1,재공유 또는 댓글을 받을 것임/학습 시스템에 이러한 통계를 제공하면 최적화 컨텍스트와 관련하여 어떠한 데이터도 갖지 않는 새로운 게시물이 추천될 수 있음
  - 라벨로 사용 중인 사용자의 행동이 있다면 다른 컨텍스트의 자료에 대해 같은 행동을 파악하여 좋은 특성을 만들 수 있음/이런 모든 특성이 새로운 콘텐츠를 조명하는 데 기여함
  - 개인별 파악은 여기에 해당하지 않음/콘텐츠를 좋아하는 사람이 있는지부터 알아낸 후에 누가 콘텐츠를 좋아하거나 싫어하는지를 알아내는 것이 순서임
- 규칙 #19:가능하면 매우 구체적인 특성을 사용하라.
  - 소수의 복잡한 특성보다는 다수의 단순한 특성을 학습하는 것이 더 간편함
  - 검색 대상 문서의 식별자 및 규격화된 쿼리는 일반화에 크게 기여하지 못하지만, 헤드 쿼리에서 순위와 라벨을 서로 맞춰주는 역할을 함
  - 특성 그룹에서 각 특성이 데이터의 매우 작은 부분에만 적용되더라도 전체 포함률이 90%를 넘는다면 걱정할 필요가 없음
  - 정규화를 사용하면 너무 적은 예시에 적용되는 특성을 배제할 수 있음
- 규칙 #20:사람이 이해할 수 있는 방식으로 기존 특성을 결합하고 수정하여 새 특성을 만들어라
  - 특성을 결합하고 수정하는 방법은 다양함/텐서플로우 같은 머신러닝 시스템은 변환을 통해 데이터를 전처리하는 방법을 제공함
  - 불연속화 및 교차라른 두 가지 표준적인 방식이 있음
  - 불연속화란 연속 특성으로부터 여러 불연속 특성을 만들어내는 과정임/기본적인 분위만 사용해도 대부분의 효과를 얻을 수 있음
  - 교차란 둘 이상의 특성 열을 결합한다는 의미임/텐서플로우에서 사용하는 '특성 열'이라는 용어는 동질 특성으로 구성된 집합({남성,여성})을 나타냄
  - 교차는 {남성,여성} x {미국,캐나다,멕시코}의 특성으로 이루어진 새로운 특성 열임/(남성,캐나다)같은 특성이 포함됨
  - 텐서플로우의 경우 교차 생성을 지시하면 캐나다 남성을 나타내는 예시인 (남성,캐나다)특성이 지정됨
  - 3가지,4가지 또는 그 이상의 기본 특성 열을 교차하여 모델을 학습시키려면 막대한 양의 데이터가 필요함
  - 매우 큰 특성 열을 산출하는 교차는 과적합을 초래할 수 있음/예를 들어 검색 기능을 만들면서 검색어의 단어를 포함하는 특성 열과 문서의 단어를 포함하는 특성 열과 문서의 단어를 포함하는 특성 열을 준비할 수 있음/이때 두 특성 열을 교차하여 결합하면 지나치게 많은 특성이 생성됨
  - 텍스트를 다룰 때는 두 가지 대안이 있음/가장 엄격한 방법은 내적을 구하는 것임/가장 단순한 형태의 내적은 검색어와 문서가 공통적으로 갖는 단어의 수를 세는 것임/그런 다음 이 특성을 불연속화함
  - 다른 방법은 교집합을 구하는 것임/'pony'라는 단어가 문서와 검색어에 모두 있을 때만 존재하는 특성 및 'the'라는 단어가 문서와 검색어에 모두 있을 때만 존재하는 특성을 준비하면 됨 
- 규칙 #21:선형 모델에서 학습 가능한 특성 가중치의 개수는 데이터 보유량에 대략적으로 비례함.
  - 학습 규모를 데이터 규모에 맞추는 것
    - 1.검색 순위 시스템을 다루고 있으며 문서와 검색어에 수백만 가지 단어가 있는데 라벨이 있는 예는 1000개뿐이라면 문서 특성과 검색어 특성의 내적, TF-IDF및 인위적으로 추출된 몇 가지 특성을 사용해야함/1000개의 예시에 10개 정도의 특성이 생김
    - 2.예시가 100만개라면 정규화 및 특성 선택을 사용해 문서 특성 열과 검색어 특성 열의 교집합을 구함/이를 통해 수백만 개의 특성이 산출되지만 정규화를 통해 특성이 감소함/1000만개의 예시에 10만 개 정도의 특성이 생김
    - 3.예시가 수십억 또는 수천억 개라면 특성 선택 및 정규화를 사용해 특성 열을 문서 및 검색어 토큰과 교차할 수 있음/10억 개의 예시에 1000만개의 특성이 생김/통계적 학습 이론은 절대적인 기준을 거의 제시하지 않지만 출발점으로 삼기에는 충분함
  - 규칙 #28에 따라 사용할 특성을 결정함
- 규칙 #22:더 이상 사용하지 않는 특성을 정리하라.
  - 미사용 특성은 기술 부채가 됨/더 이상 사용되지 않는 특성이 있고 다른 특성과 결합해도 유용성이 없는 경우 인프라에서 삭제하라
  - 인프라를 깔끔하게 유지해야 가장 유망한 특성을 최대한 빠르게 시험해 볼 수 있음/특성이 다시 필요해지면 언제든지 다시 추가할 수 있음
  - 추가하거나 유지할 특성을 결정할 떄는 포괄 범위를 고려하라/특성이 얼마나 많은 예시를 포괄하는가?
  - 어떤 특성은 생각보다 큰 역할을 하기도 함/예를 들어 데이터 중 1%만을 포괄하는 특성이 있는데 해당 특성을 갖는 예시 중 90%가 양성이라면 꼭 추가해야 할 특성임
  
## 인간에 의한 시스템 분석
- 기존 모델을 어떻게 바라보고 개선할지에 관한 것/바람직하지 않은 몇 가지 패턴을 피하는 데 도움이 됨 
- 규칙 #23:나는 전형적인 최종 사용자가 아니다
  - 성능의 정확성에 대해 살펴야 함/프로덕션 단계에 근접했다고 판단되는 요소를 철저히 테스트하는 것이 더 중요함
  - 개발자는 코드부터 신경쓰기 마련이고 게시물의 특정한 측면에만 주목하거나 지나치게 감정이 개입되어 확증 편향에 휩쓸릴 수 있음
  - 개발자의 시간은 중요함
  - 사용자의 의견이 꼭 필요할 시 사용자 경험 방법론을 사용하라/프로세스 초기에 사용자 페르소나를 만들고 이후에 사용성 테스트를 진행
  - 사용자 페르소나는 가상적인 사용자를 의미함
- 규칙 #24:모델 사이의 델타를 측정하라
  - 새 모델을 접하기 전에 측정할 수 있는 가장 쉽고도 유용한 항목/새로운 결과가 프로덕션의 기존 결과와 얼마나 다른지를 계산하는 것을 들 수 있음
  - 예를 들어 순위 결정 문제에서 전체 시스템을 통해 쿼리 샘플을 대상으로 두 모델 실행후 결과의 대칭 차 크기에 순위별 가중치를 적용
    - 차이가 매우 작다면 별도의 실험을 거치지 않고 변화가 거의 없을 것을 짐작할 수 있음
    - 차이가 매우 크다면 긍정적인 변화임을 확증할 수 있어야함
  - 대칭 차가 크게 나온 쿼리를 살펴보면 변화의 본질적인 측면을 이해하는 데 도움이 됨
  - 시스템의 안정성이 중요함/모델을 자기 자신과 비교했을 때의 대칭 차가 낮은지 확인하라/0으로 나오면 가장 좋음
- 규칙 #25:모델을 선택할 때는 예측 능력보다 실용적인 성능을 우선시하라.
  - 모델에서 클릭률을 예측하려고 할 것이지만 그 예측으로 무엇을 할 지가 중요함
  - 문서의 순위를 결정하는 데 활용할 생각이라면 예측 자체보다는 최종적인 순위의 품질이 더 중요함
  - 문서가 스팸일 확률을 예측하여 차단 기준을 정할 계획이라면 허용되는 대상의 정확성이 가장 중요함
  - 이러한 두 관점이 조화를 이루는 것이 대부분
  - 어떠한 변화가 로그 손실을 개선하지만 시스템의 성능을 떨어뜨리면 다른 특성을 봐야함/이런 상황이 자주 나타나면 모델의 목표를 재검토해야함
- 규칙 #26:측정 오차에서 패턴을 찾아 새 특성을 만들어라.
  - 머신러닝 시스템에서 예측이 잘못되었음을 스스로 알고 있으므로 기회가 있으면 수정이 가능함/오류를 수정할 수 있는 특성을 모델에 제공하면 모델은 이 특성을 사용하려고 함
  - 시스템에서 실수를 깨닫지 못한 예시를 기반으로 만들어진 특성은 무시됨
  - 모델에서 잘못 예측한 예시를 확보했으면 현재 특성 집합을 벗어나는 추세를 찾음
    - 예를 들어 시스템에서 긴 게시물의 순위를 낮추는 경향이 발견되면 게시물 길이를 추가함/구체적일 필요 없음
    - 길다는 의미의 기준을 어림짐작할 필요 없이 단순히 10개의 특성을 추가한 후 모델이 알아서 판단하도록 놔둬라
- 규칙 #27:부적절한 동작이 관찰되면 정량화를 시도하라.
  - 시스템에 바람직하지 않은 속성이 있는데 기존 손실 함수로는 포착되지 않아서 곤란한 상황이 올 수 있음
  - 이러한 경우 어떤 수를 써서라도 불만족스러운 점을 구체적인 숫자로 바꿔놓아야 함
  - 측정 가능한 문제점이라면 이제부터 특성, 목표 또는 측정항목으로 사용할 수 있음/일반적인 규칙은 측정 후 최적화임
- 규칙 #28:단기적인 동작이 같더라도 장기적인 동작은 다를 수 있음
  - 시스템 자체 기록을 기반으로 해당 쿼리에 관한 문서만을 보여주고 새 문서를 표시해야 한다는 사실을 학습을 할 수 없는 경우도 있음
  - 이러한 경우 장기적으로 어떻게 작동할지 알아내는 유일한 방법은 모델이 실제로 운영될 때 획득한 데이터로만 학습하는 것인데 매우 어려운 일임

## 학습-서빙 격차
- 학습-서빙 격차란 학습 시 성능과 서빙 시 성능 간의 차이를 뜻함/다음과 같은 원인이 있음
  - 학습 파이프라인과 서빙 파이프라인에서 데이터를 처리하는 방법의 차이
  - 학습 시 데이터와 제공 시 데이터 간의 변화
  - 모델과 알고리즘 간의 피드백 루프
- 학습-서빙 격차로 인해 성능이 저하된 경우가 있음/가장 좋은 해법은 시스템과 데이터 변화로 인해 예기치 않은 격차가 생기지 않도록 모니터링하는 것임
- 규칙 #29:학습 환경을 서빙 환경과 일치시키는 최선의 방법은 서빙 시에 사용된 특성 세트를 저장해 두었다가 로그에 공급하여 학습 시에 사용하는 것임
  - 모든 예시에 대해서 불가능하다면 일부 예시에 대해서라도 실천하여 서빙과 학습의 일관성을 검증할 방법을 강구해야함
- 규칙 #30:표본 추출된 데이터를 임의로 무시하지 말고 중요도에 따라 가중치를 매겨라.
  - 사용자에게 한 번도 표시되지 않은 데이터는 삭제해도 무방하지만, 나머지 데이터에는 중요도 가중치를 적용하는 것이 좋음
  - 중요도 가중치랑 예시 x를 샘플링할 확률이 30%라면 10/3의 가중치를 준다는 의미임/중요도 가중치를 사용하는 경우에도 규칙#14에서 설명한 보정 속성이 모두 적용됨
- 규칙 #31:학습 및 서빙 시에 테이블의 데이터를 조인하는 경우 테이블의 데이터는 달라질 수 있음을 명시하라.
  - 규칙 #31의 내용과 같이 학습과 서빙 간에 같은 문서에 관한 모델의 예측이 서로 달라지는 경우가 생길 수 있음
  - 이와 같은 문제를 피하기 위해 서빙 시에 특성을 기록하는 것도 방법임
  - 테이블의 변화가 비교적 느리다면 1시간 또는 하루마다 테이블의 스냅샷을 만들어 적당히 근접한 데이터를 얻을 수 있음/완벽한 문제 해결은 아님
- 규칙 #32:가능하면 학습 파이프라인과 서빙 파이프라인 간에 코드를 재사용하라.
  - 서빙 시에는 온라인 처리를 학습 시에는 일괄 처리를 함/그러나 코드를 재사용할 수 있는 방법이 있음
  - 예를 들어 모든 쿼리 또는 조인의 결과를 사람이 읽을 수 있는 방식으로 저장하는 시스템 고유 개체를 만들면 오류를 쉽게 테스트 할 수 있음
  - 모든 정보가 수집되었으면 서빙 또는 학습 중에 공통 메소드를 실행하여 사람이 읽을 수 있는 시스템 고유 개체와 머신러닝 시스템에 사용되는 형식 사이에 다리를 놓으면 학습-서빙 격차가 근본적으로 방지됨
  - 학습 코드와 서빙 코드에 동일한 프로그래밍 언어를 사용해야함
- 규칙 #33:1월 5일까지 수집된 데이터를 기준으로 모델을 생성하는 경우 1월 6일 이후의 데이터로 모델을 테스트하라.
  - 일반적인 규칙은 모델 학습에 사용된 데이터보다 이후에 수집된 데이터로 모델의 성능을 측정하는 것임
  - 이렇게 하면 시스템의 프로덕션 성능을 더 정확히 예상할 수 있음
  - 새 데이터에 관한 성능은 기존 데이터보다 다소 저하되는 것이 정상이지만 크게 나빠져서는 안됨
  - 우연하 일별 변동이 작용할 수 있으므로 평균적인 클릭률 또는 전환율이 나오지 않을 수도 있지만, 양성 예시가 음성 예시보다 1점 높게 나올 가능성을 나타내는 AUC는 합리적인 수준의 유사성을 보여야함
- 규칙 #34:스팸 감지, 관심 이메일 판단 등 필터링을 위한 이진 분류에서는 단기적으로 다소의 성능 저하를 감수하더라도 데이터를 철저히 정제하라.
  - 필터링 작업에서는 음성으로 판정된 예시를 사용자로부터 숨김/ 서빙 시 음성 예시의 75%를 차단하는 필터가 있다고 가정해보자
  - 사용자에게 표시된 인스턴스로부터 추가적인 학습 데이터를 추출하려는 생각이 들 수 있음/필터를 통과했지만 사용자가 스팸으로 신고한 이메일은 학습 데이터로 활용할 수 있음
  - 이 접근법은 샘플링 편향을 유발함/더 정제된 데이터를 얻는 방법은 서빙 시 전체 트래픽 중 1%를 '홀드아웃'으로 라벨링하고 모든 홀드아웃 예시를 사용자에게 보내는 것임/필터는 음성 예시 중에서 최소 74%를 차단함/이러한 예시는 학습 데이터가 될 수 있음
  - 필터가 음성 예씨의 95% 이상을 차단한다면 이 접근법은 현실성이 낮음/서빙 성능을 측정하려는 경우 소량의 샘플(0.1% 또는 0.001%)을 추출할 수 있음/1만 개 정도의 예시가 있으면 성능을 비교적 정확히 추정할 수 있음
- 규칙 #35:순위 결정 문제에서는 특유의 왜곡이 나타날 수 있음
  - 표시되는 결과가 바뀔 정도로 순위 결정 알고리즘을 급격히 변경하면 알고리즘에서 이후에 접하게 될 데이터 자체가 변화하는 결과를 낳음
  - 이러한 유형의 왜곡이 나타날 것을 대비하여 모델을 설계해야함/여러 가지 접근법이 있으며, 공통점은 모델에서 기존에 접한 데이털르 우선시한다는 점임
    - 1.쿼리 하나에만 해당하는 특성보다 여러 쿼리를 포괄하는 특성에 더 높은 정규화를 적용함/모델에서 모든 쿼리로 일반화되는 특성보다 하나 또는 소수의 쿼리에 국한되는 특성이 우선시됨/매우 흔히 나타나는 결과가 이와 무관한 쿼리에까지 영향을 주지 않도록 차단하는 데 도움이 됨/고유 값이 더 많은 특성 열에 더 높은 정규화를 적용하라는 기존의 권장사항과 정반대임
    - 2.특성에 양수 가중치만을 허용함/양호한 모든 특성이 '미지의'특성보다 우선시됨
    - 3.문서에만 국한된 특성을 배제함/#1의 극단적인 경우/특정 앱이 쿼리와 무관하게 많은 다운로드르 기록했더라도 무조건 항상 표시할 수는 없음/문서에만 국한된 특성을 배제하면 문제가 더 단순해짐
- 규칙 #36:위치 특성을 사용하여 피드백 루프를 방지하라.
  - 콘텐츠의 위치는 사용자와의 상호작용에 막대한 영향을 줌/이 문제를 다루는 방법 중 하나는 위치 특성, 즉 페이지에서 콘텐츠가 차지하는 위치에 관한 특성을 추가하는 것임
  - 모델 학습에 위치 특성을 사용하면 '1stposition'과 같은 특성에 높은 가중치를 부여하도록 모델이 학습됨/'1stposition=true'를 갖는 예시에서는 다른 요소에 적은 가중치가 부여됨
  - 서빙 시에는 후보의 점수를 매긴 후에 표시 순서를 결정하게 되므로 모든 인스턴스에 위치 특성을 지정하지 않거나 동일한 기본 특성을 지정함
  - 위치 특성은 이와 같이 학습과 제공 간에 비대칭성을 가지므로 모델의 나머지 부분과 별도로 유지하는 것이 중요함/모델을 위치 특성의 함수와 나머지 특성의 함수를 더한 합으로 만드는 것이 가장 좋음/위치 특성과 문서 특성을 교차해서는 안됨
- 규칙 #37:학습/서빙 격차를 측정하라.
  - 격차가 발생할 수 있는 원인은 일반적으로 몇 가지로 정리되며 다음과 같이 몇 부분으로 나눌 수 있음
    - 학습 데이터와 홀드아웃 데이터 간의 성능 차이.일반적으로 이 차이는 불가피하며 반드시 나쁜 것은 아님
    - 홀드아웃 데이터와 '다음날'데이터 간의 성능 차이. 이 차이도 불가피함. 다음날 성능을 극대화하는 방향으로 정규화를 조정해야함/홀드아웃 데이터와 다음날 데이터 간에 상당한 격차가 있다면 일부 특성에 시간 민감성이 있어 모델의 성능을 저하한다는 증거일 수 있음
    - '다음날' 데이터와 실시간 데이터 간의 성능 차이/학습 데이터의 예시에 모델을 적용할 때와 서빙 시 동일한 예시에 모델을 적용할 때 완전히 같은 결과가 나와야함

## ML 3단계:성장 둔화,최적화 개선,복합 모델 
- 2단계가 마무리되고 있음을 나타내는 구체적인 징후가 있음/월별 개선 폭이 둔화하기 시작함/측정항목 간에 절충 관계가 나타나기 시작함
- 몇몇 실험에서 상승하는 측정항목과 하락하는 측정항목이 동시에 나타남/여기서부터 문제가 복잡해짐
- 개선을 이루기가 어려워졌기 때문에 머신러닝 시스템을 정교화해야함
- 이 섹션에서부터 다소 비현실적인 규칙이 포함될 수 있으므로 스스로 길을 찾아 나가야함
- 규칙 #38:목표 불일치가 문제가 되었다면 새로운 특성에 시간을 낭비하지 말라.
  - 측정항목 개선이 한계에 다다르면 현재 머신러닝 시스템의 목표에서 벗어난 문제점을 찾기 시작할 때임
  - 기존의 알고리즘 목표로는 제품의 목표를 해결할 수 없다면 알고리즘 목표와 제품 목표 중 하나를 변경해야함
- 규칙 #39:출시 결정은 제품의 장기적인 목표를 반영해야 함
  - 출시 결정에는 여러 가지 기준이 작용하며 ML을 통해 최적화할 수 있는 것은 그 중 일부에 불과함
  - 수집 가능한 통계를 총동원하여 시스템의 미래 성능을 효과적으로 예측하기 위해 노력해야함
  - 출시 결정을 내리기 쉬운 유일한 경우는 모든 측정항목이 개선되거나 적어도 악화되지 않을 때임
  - 자신이 직접 최적화할 수 있는 측정항목 하나를 중시하는 경향이 있음/대부분 머신러닝 도구는 이러한 환경에 적합함
  - 이러한 환경에서는 새로운 특성을 개발하는 엔지니어가 끊임없이 계속되는 출시에 대응해야함/머신러닝 유형 중 이 문제를 다루기 시작하는 유형이 다중 목표 학습임/예를 들어 각 측정항목에 관한 하한선을 갖는 제약조건 충족 문제를 작성하고 측정항목의 특정한 선형 조합을 최적화할 수 있음/그렇게 하더라도 모든 측정항목을 머신러닝 목표로 손쉽게 규격화할 수 있는 것은 아님
- 규칙 #40:앙상블을 단순하게 유지하라.
  - 원시 특성을 취하여 콘텐츠의 순위를 바로 결정하는 통합 모델은 디버깅 및 파악이 가장 쉬운 모델임
  - 모델의 앙상블(다른 모델의 점수를 종합하여 만든 단일 '모델')은 더 우수한 성능을 발휘할 수 있음
  - 단순성을 유지하려면 각 모델은 다른 모델의 입력만을 취하는 앙상블이거나 여러 특성을 취하는 기본 모델이어야 하며, 두 가지 입력을 모두 취해서는 안됨
  - 별도로 학습되는 다른 모델을 기반으로 하는 여러 모델이 있는 경우 이러한 모델을 결합하면 부적합한 동작이 나타날 수 있음
  - 앙상블에는 '기본'모델의 출력만을 입력으로 취하는 단순 모델을 사용하라/이러한 앙상블 모델의 속성을 직접 규정할 필요가 있음
  - 예를 들어 기본 모델이 산출하는 점수가 상승하는 경우 앙상블의 점수가 하락해서는 안됨/가급적이면 입력 모델이 의미론적으로 해석 가능하도록 보정 등의 작업을 거쳐야함/그래야만 기반 모델의 변화가 앙상블 모델에 혼선을 주지 않음
  - 기반 분류자가 예측한 확률이 상승할 때 앙상블이 예측한 확률이 하락하지 않도록 강제해야함
- 규칙 #41:성능 개선이 한계에 봉착했다면 기존 신호를 다듬기보다는 본질적으로 새로운 정보 출처를 찾아서 추가하라.
  - 새로운 정보를 추가함에따라 완전히 다른 특성을 위한 인프라 구축을 시작해야함
- 규칙 #42:다양성,맞춤화 또는 관련성은 인기도와 상관관계가 의외로 낮을 수 있음
  - 콘텐츠 집합의 다양성은 여러 가지 의미를 가질 수 있음/가장 흔한 것은 콘텐츠 출처의 다양성을 의미하는 경우임
  - 맞춤화란 각 사용자에게 자신만의 결과를 제공하는 것임
  - 관련성이란 특정 쿼리의 결과가 다른 어떠한 결과보다도 해당 쿼리에 적합하다는 의미임
  - 이러한 세 가지 속성은 평범하지 않은 특별한 속성으로 규정됨
  - 그러나 평범함이 최선인 경우도 많음
  - 후처리를 통해 다양성 또는 관련성을 강화할 수 있음/더 장기적인 목표가 개선되는 것으로 나타난다면 인기도와는 별개로 다양성/관련성이 중요하다고 판단할 수 있음/후처리를 계속 사용할 수도 있고, 다양성 또는 관련성을 기준으로 목표를 직접 수정할 수도 있음
- 규칙 #43:제품은 달라도 친구는 비슷하나, 관심사는 그렇지 않음.
  - 한 제품에서 관계의 긴밀함을 예측하는 모델을 취하여 다른 제품에 성공적으로 적용함으로써 큰 성과를 거둘 수 있음
  - 반면, 여러 제품 분야를 넘나드는 맞춤화 특성으로 인해 고생하는 경우도 있음
  - 성공해야 할 것 같다가도, 실제로는 잘 되지 않을 수 있음
  - 한 부문의 원시 데이터를 사용하여 다른 부문의 사용자 행동을 예측하는 방법은 성공을 거두기도 함
  - 사용자가 다른 부문에서 활동한 적이 있다는 사실만 알아도 도움이 될 수 있음
  
  
