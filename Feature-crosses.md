## 특성 교차
- 방식의 이름/양식 [A X B]의 템플릿을 정의함
- 양식이 더 복잡할 수 있음 [A X B X C X D X E]
- A와 B가 빈과 같은 부울 특성인 경우 곱의 결과 범위가 매우 희소하게 나타날 수 있음 
- 예
  - 주택시장 가격 예측: [latitude X num_bedrooms]
  - 틱택토 예측: [pos1 x pos2 x ... x pos9]
### 특성 교차를 사용해야 하는 이유
- 선형 학습자는 대량의 데이터(예:Vowpal Wabbit, sofia-ml)에 맞게 적절히 확장됨 
- 특성 교차가 없으면 모델을 충분히 표현할 수 없음 
- 특성 교차와 대량의 데이터를 사용하면 매우 복잡한 모델을 효율적으로 학습할 수 있음 
  - 신경망을 사용할 수도 있음 


## 특성 교차:비선형성 인코딩 
- 파란색 점은 병든 나무를 나타냄
- 주황색 점은 건강한 나무를 나타냄 
- 선을 기준으로 나무의 상태를 적절히 예측할 수 있음 
<img src="https://user-images.githubusercontent.com/32586985/70212855-6ddf7a00-177b-11ea-8ac9-8bb7ca02be06.PNG">

- 병든 나무와 건강한 나무를 깔끔하게 구분하는 직선을 그릴 수 없음/어떤 선을 그려도 나무의 상태를 적절히 예측할 수 없음 
<img src="https://user-images.githubusercontent.com/32586985/70213052-cf9fe400-177b-11ea-8918-71ca935fae72.PNG">

- 비선형 문제 
<img src="https://user-images.githubusercontent.com/32586985/70212951-9d8e8200-177b-11ea-9c3f-a7b893e8aa6d.PNG">

- 그림 2에 표시된 비선형 문제를 해결하려면 특성 교차를 만들어야함 
- 특성 교차는 두 개 이상의 입력 특성을 곱하여 특성 공간에서 비선형성을 인코딩하는 합성 특성임 
- x1과 x2를 교차하여 x3이라는 특성 교차를 만듬 
<img src="https://user-images.githubusercontent.com/32586985/70213163-0ece3500-177c-11ea-96fa-6f872f7d50d3.PNG">

- 선형 수식은 다음과 같음 
- w3의 가중치를 학습할 수 있음/w3이 비선형 정보를 인코딩해도 w3의 값을 결정하기 위해 선형 모델의 학습 방식을 변경하지 않아도 됨 
<img src="https://user-images.githubusercontent.com/32586985/70213212-2a394000-177c-11ea-82f4-4a533b17a376.PNG">

### 특성 교차의 종류
- 여러 종류의 특성 교차를 만들 수 있음 
  - [A X B]: 두 특성의 값을 곱하여 구성되는 특성 교차
  - [A X B X C X D X E]: 다섯 개의 특성 값을 곱하여 구성되는 특성 교차
  - [A X A]: 단일 특성을 제곱하여 구성되는 특성 교차
- 확률적 경사하강법을 활용하여 선형 모델을 효율적으로 학습시킬 수 있음 
- 예전부터 조정된 선형 모델을 특성 교차로 보완하는 방법으로 모델을 대규모 데이터 세트에 효율적으로 학습시켜옴 


## 특성 교차:원-핫 벡터 교차
- 별개의 두 부동 소수점 특성의 특성 교차에 초점을 맞추었지만 실제로는 연속 특성을 교차하는 경우는 거의 없음 
- 원-핫 특성 벡터의 특성 교차는 논리적 결합이라고 할 수 있음 
- 예를 들어 국가와 언어, 두 특성이 있다고 가정
  - 각 특성을 원 핫 인코딩하면 country=USA,country=France 또는 language=English,language=Spanish로 가능
  - 위와 같이 해석할 수 있는 이진 특성이 포함된 벡터가 생성됨
  - 이러한 원-핫 인코딩의 특성을 교차하여 다음과 같이 논리적 결합으로 해석할 수 있는 이진 특성이 생성됨
  ```python
     country:usa AND language:spanish
  ```
- 위도와 경도를 비닝하여 다섯 개의 요소로 구성된 별도의 원-핫 특성 벡터를 만든다고 가정
  ```python
     binned_latitude = [0, 0, 0, 1, 0]
     binned_longitude = [0, 1, 0, 0, 0]
     # 다음과 같이 표현 가능 
  ```
  - 이 두 특성 벡터의 특성 교차를 만든다고 가정 
  ```python
     binned_latitude X binned_longitude
  ```
  - 이 특성 교차는 25개의 요소로 구성된 원-핫 벡터임(24개의 0과 1개의 1)
  - 교차에 있는 1개의 1은 위도와 경도의 특정 결합을 나타냄/해당 결합의 특정 연결을 학습할 수 있음 
- 위도와 경도를 훨씬 더 넓은 간격으로 비닝한다고 가정 
  ```python
     binned_latitude(lat) = [
       0  < lat <= 10
       10 < lat <= 20
       20 < lat <= 30
     ]
     
     binned_longitude(lon) = [
       0  < lon <= 15
       15 < lon <= 30
     ]  
  ```
    - 다음과 같은 의미의 합성 특성이 생성됨 
    ```python
       binned_latitude_X_longitude(lat, lon) = [
         0  < lat <= 10 AND 0  < lon <= 15
         0  < lat <= 10 AND 15 < lon <= 30
         10 < lat <= 20 AND 0  < lon <= 15
         10 < lat <= 20 AND 15 < lon <= 30
         20 < lat <= 30 AND 0  < lon <= 15 
         10 < lat <= 30 AND 15 < lon <= 30
       ]   
    ```
- 모델에서 두 특성을 기반으로 개 주인이 개에 만족하는 정도를 예측해야 한다고 가정 
  - 행동 유형(짖기,울기,달라붙기 등)
  - 시간 
- 두 특성의 특성 교차를 만들면 
```python
   [behavior type X time of day]
```
- 특성 하나만 사용하는 경우보다 훨씬 더 효과적으로 예측할 수 있음 
- 선형 학습자는 대량의 데이터에 적합하게 확장됨/대량의 데이터에 특성 교차를 사용하면 매우 복잡한 모델을 효율적으로 학습할 수 있음 
- 신경망을 통해 다른 전략을 사용할 수도 있음 
