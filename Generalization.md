## 일반화  
<img src="https://user-images.githubusercontent.com/32586985/69316836-fd196780-0c7c-11ea-959f-620dad0336bb.PNG">

- 목표: 숨겨진 실제 분포에서 추출된 새로운 데이터를 제대로 예측
- 문제: 진실을 알 수 없음 
    - 분포에서 추출된 샘플만 볼 수 있음 
- 모델 h가 현재 샘플에 적합하면 다른 새로운 샘플도 잘 예측할 것이라고 신뢰할 수 있을것인가?

## 모델이 적합한지 어떻게 알 수 있을까?
- 이론적인 측면:
    - 흥미로운 분야: 일반화 이론
    - 모델의 단순성/복잡성 측정 아이디어를 기반으로 함
- 직관: 오컴의 면도날 원칙의 형상화
    - 모델이 덜 복잡할수록 샘플 자체의 특성을 벗어나 좋은 경험적 결과를 얻을 가능성이 높음 
- 경험적인 측면:
    - 질문: 모델이 새로운 데이터 샘플에 효과적으로 작동하나요?
    - 평가: 새로운 데이터 샘플을 얻습니다.(테스트 세트라고 함).
    - 모델이 테스트 세트에서 효과적으로 작동하면 다음과 같은 경우 새로운 데이터에도 잘 작동할 것이라고 추정할 수 있음 
        - 테스트 세트가 충분히 큰 경우
        - 테스트 세트를 반복적으로 사용하지 않는 경우 
    
## ML 세부사항
- 위의 경우 모두 기본적으로 다음 세 가지를 가정함 
  - 1. 분포에서 독립적이고 동일한 방식으로(i.i.d.)임의로 예를 추출함 
  - 2. 분포가 정상성을 보이며 시간이 지나도 변하지 않음
  - 3. 학습,유효성 검사 및 테스트 세트를 항상 같은 분포에서 추출함  
- 이러한 가정을 염두에 두고 측정항목에 특히 주의해야함/언제든지 가정은 바뀔 수 있음 


## 일반화: 과적합의 위험 
- 일반화의 초점을 맞추고 세 개의 그림을 통해 일반화 개념을 생각해보자
- 그림의 각 점은 숲에서 나무의 위치를 나타낸다고 가정함
  - 파란색 점은 병든 나무
  - 주황색 점은 건강한 나무
- 그림 1. 병든(파란색) 나무와 건강한(주황색) 나무
<img src="https://user-images.githubusercontent.com/32586985/69317595-9dbc5700-0c7e-11ea-85bd-ed45b01e677f.PNG">

- 그림 2. 특정 머신러닝 모델에서 병든 나무와 건강한 나무를 구분하는 방법
- 이 모델은 손실이 매우 적게 발생함/아주 적합한 것처럼 보이지만 실제로도 그럴까?
<img src="https://user-images.githubusercontent.com/32586985/69317680-d0fee600-0c7e-11ea-840b-721d1d704b1d.PNG">

- 모델에 새 데이터를 추가할 때 어떤 일이 발생했는지 보여줌 
- 모델이 새 데이터에 적합하지 않은 것으로 확인됨/모델이 새 데이터 대부분을 잘못 분류함 
- 그림 3. 새 데이터를 잘못 예측한 모델 
<img src="https://user-images.githubusercontent.com/32586985/69317784-0f94a080-0c7f-11ea-888b-aeba587e4312.PNG">

- 그림 2,3에 표시된 모델은 학습한 데이터의 특성에 과적합함 
- 과적합 모델은 학습하는 동안 손실이 적지만 새 데이터를 잘 예측하지 못함 
- 필요 이상의 복잡한 모델을 만들면 과적합이 발생함/머신러닝의 근본적인 과제는 데이터 적합도를 유지하는 동시에 최대한 단순화하는 것
- 머신러닝의 목표는 숨겨진 실제 확률 분포에서 추출되는 새 데이터를 잘 예측하는 것임
  - 하지만 모델에서는 모든 데이터를 볼 수 없으며 학습 데이터 세트에서만 샘플을 추출할 수 있음 


### 오컴의 면도날 법칙
- 오컴은 단순성을 좋아함/과학자는 복잡한 것보다 간단한 공식이나 이론을 선택해야 한다고 생각함 
- ML모델이 덜 복잡할수록 샘플의 특성 때문이 아니어도 좋은 경험적 결과를 얻을 가능성이 높음 
- 오컴의 면도날 법칙을 공식화함/다음과 같은 요인을 기반으로 새 데이터에 맞게 모델이 일반화되는 정도를 통계적으로 설명하는 일반화 한계 개발
  - 모델의 복잡성
  - 학습 데이터에 대한 모델의 성능 
- 이론적 분석은 이상적인 가정하에 형식적인 결과를 보장하지만 실제로 적용하기 어려울 수 있음 
- 경험적 평가에 초점을 맞춰 새 데이터에 맞게 모델이 일반화되는 정도를 판단함 
- 머신러닝의 목표는 이전에 보지 못한 새 데이터를 잘 예측하는 것임 
  - 어떻게 이전에 보지 못한 데이터를 얻을 수 있을까?
    - 학습 세트: 모델을 학습시키기 위한 하위 세트
    - 테스트 세트: 모델을 테스트하기 위한 하위 세트 
  - 테스트 세트에서 성능이 좋으면 일반적으로 다음과 같은 경우 새 데이터에서도 성능이 좋음 
    - 테스트 세트가 충분히 큽니다
    - 같은 테스트 세트를 반복 사용하지 않습니다
    
    
## ML 세부사항  
- 일반화에서는 기본적으로 다음 세 가지 사항을 가정함 
  - 분포에서 독립적이고 동일하게(i.i.d.)임의로 예를 추출함/예가 서로 영향을 미치지 않음(i.i.d.는 변수의 임의성을 가리키는 한 가지 방법)
  - 분포가 정상성을 보임/데이터 세트 내에서 분포가 달라지지 않음 
  - 같은 분포를 따르는 부분에서 예를 추출함 
- 실제로는 이러한 가정을 위반하는 경우가 있음 
  - 표시할 광고를 선택하는 모델을 고려하는 경우.모델이 선택된 광고,부분적으로 사용자가 이전에 본 광고를 기반으로 하는 경우 i.i.d. 가정을 위반하게 됨 
  - 1년 동안의 소매 판매 정보가 포함된 데이터 세트를 고려하는 경우.사용자의 구매 패턴이 계절에 따라 변경되어 정상성을 위반하게 됨 
- 앞의 세 가지 가정을 위반한 것이 확인되면 측정항목에 세심하게 주의를 기울여야 함.   
  
