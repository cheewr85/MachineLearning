## 학습 및 테스트 세트
- 테스트 세트는 학습 세트로부터 개발한 모델을 평가하는 데 사용되는 데이터 세트임 

## 데이터 세트가 하나뿐이라면 어떻게 하나요?
- 다음과 같이 두 세트로 분할함 
  - 학습 세트
  - 테스트 세트
- 기억해야 할 유의사항:테스트 데이터로 학습하지 않기
  - 손실이 이상할 정도로 적은가요?
  - 실수로 테스트 세트로 학습하진 않았는지 확인하기

## 데이터 분할
- 학습 세트: 모델을 학습시키기 위한 데이터 세트의 일부분
- 평가 세트: 모델을 테스트하기 위한 데이터 세트의 일부분 
- 그림 1. 데이터 세트 하나를 학습 세트와 평가 세트로 분할
<img src="https://user-images.githubusercontent.com/32586985/69318959-95195000-0c81-11ea-9384-6cad6a34d3ae.PNG">

- 평가 세트는 다음 두 가지 조건을 만족해야함 
  - 통계적으로 유의미한 결과를 도출할 만큼 커야함 
  - 데이터 세트를 전체적으로 나타내야함/평가 세트가 학습 세트와 같은 특징을 가지도록 선별해야함 
- 평가 세트가 위와 같은 두 가지 조건을 만족한다면 이제 새로운 데이터에도 일반화 될 수 있는 모델을 만드는 것이 목표 
- 평가 세트는 새 데이터를 모의 실험하는 역할을 함 
- 다음의 예
  - 학습 데이터를 익힌 모델은 단순함/모델은 그다지 완벽하지 않으며 몇 가지 예측이 빗나감 
  - 테스트 데이터에 대한 결과는 학습 데이터에 대한 결과에 비해 나쁘지 않음 
  - 이 단순 모델은 학습 데이터에 과적합되지 않음 
- 그림 2. 학습된 모델을 테스트 데이터로 검증 
<img src="https://user-images.githubusercontent.com/32586985/69319258-2c7ea300-0c82-11ea-875b-99783c616b57.PNG">

- 테스트 데이터로 학습하지 마라
  - 평가 측정항목에서 이상할 정도로 좋은 결과가 나온다면 실수로 평가 세트로 학습했다는 증거일 수 있음 
  - 정확도가 높다면 테스트 데이터가 학습 세트로 유출되었을 수 있음 
- 예를 들어 제목,본문,보낸 사람의 이메일 주소를 특성을 사용하여 스팸 메일을 가려내는 모델이 있다고 가정 
  - 데이터를 80:20 비율로 학습 세트와 평가세트로 배분함 
  - 학습 후에 모델은 학습 세트와 평가 세트 모두에서 99%의 정확성을 보임 
  - 평가 세트에서는 정확성이 이보다 낮아야 하므로 데이터를 다시 살펴본 결과 평가 세트의 예 중 다수가 학습 세트의 예와 중복되는 것으로 나타남
  - 데이터를 분할하기 전에 입력 데이터베이스에서 동일한 스팸 메일의 중복항목을 솎아내지 않았던 것 
  - 테스트 데이터 중 일부가 의도치 않게 학습에 사용되어, 모델이 새 데이터로 얼마나 효과적으로 일반화되는지 정확히 측정할 수 없게됨 



## 학습 및 평가 세트
- 학습 세트 및 테스트 세트 실험 
- 각 파란색 점은 한 데이터 클래스(예:스팸)의 한 가지 예를 나타냄 
- 각 주황색 점은 다른 데이터 클래스(예:스팸이 아님)의 한 가지 예를 나타냄 
- 배경색은 해당 색상의 예가 나타날 것으로 모델에서 예측한 위치를 나타냄 
- 파란색 점 주위의 배경이 파란색이면 모델이 해당 예를 정확히 예측한 것임 
- 반대로, 파란색 점 주위의 배경이 주황색이면 모델이 해당 예를 잘못 예측한 것임 
- 학습 사례는 윤곽선이 흰색임/평가 사례는 윤곽선이 검은색임 
### 작업 1
<img src="https://user-images.githubusercontent.com/32586985/69323025-45d71d80-0c89-11ea-8581-9d4b7ee6c6d4.PNG">

- 학습률을 초기 설정과 같이 3으로 설정하면 테스트 손실이 학습 손실보다 훨씬 큼 

### 작업 2
<img src="https://user-images.githubusercontent.com/32586985/69323478-268cc000-0c8a-11ea-8dd0-5aacb0a8a58f.PNG">
<img src="https://user-images.githubusercontent.com/32586985/69323348-e594ab80-0c89-11ea-90cb-4a392394c6e4.PNG">
<img src="https://user-images.githubusercontent.com/32586985/69323357-e9c0c900-0c89-11ea-9f82-16e576a0f502.PNG">
<img src="https://user-images.githubusercontent.com/32586985/69323492-2ee4fb00-0c8a-11ea-92aa-f5d3e5222b55.PNG">

- 학습률을 0.001로 낮추면 테스트 손실이 학습 손실과 매우 유사한 값으로 하락함 
- 대부분의 실행에서는 배치 크기를 늘려도 학습 손실 또는 테스트 손실에 유의미한 영향이 없음 
- 실행 중 소수에서는 배치 크기를 20이상으로 늘릴 때 테스트 손실이 학습 손실보다 약간 낮은 값으로 하락함 

### 선택적 작업 3 
- 학습/테스트 데이터 비율을 통해서 평가 데이터와 학습 데이터의 비율을 조절함 
  - 90%로 설정하면 학습 세트에 평가 세트보다 훨씬 많은 예가 포함됨 
  - 10%로 설정하면 학습 세트에 평가 세트보다 훨씬 적은 예가 포함됨 
- 다음을 수행 
  - 1.학습/평가 데이터 비율을 50%에서 10%로 줄임 
  - 2.학습률 및 배치 크기에 변화를 주면서 관찰 결과를 기록함 
<img src="https://user-images.githubusercontent.com/32586985/69324185-55effc80-0c8b-11ea-8da3-46a97051c61e.PNG">
<img src="https://user-images.githubusercontent.com/32586985/69324200-5b4d4700-0c8b-11ea-9110-300e2cfc7b47.PNG">

- 학습/평가 데이터 비율을 50%에서 10로 줄이면 학습 세트의 데이터 포인트 수가 급격히 감소함
- 데이터가 이렇게 적은데도 배치 크기와 학습률이 높으면 학습 모델이 최저점을 넘나들며 불규칙적으로 크게 변화하는 현상이 반복됨 
