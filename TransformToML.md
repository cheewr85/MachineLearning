# 데이터에서 학습
간단한 방법에서부터 시작해 더 광범위하고 유용한 방법으로 접근함  

## 회귀에 사용할 때 편리한 손실 함수  
- 주어진 예의 L2 손실은 제곱 오차라고도 함  
  - 예측과 라벨 간의 차이 제곱
  - (관찰 - 예측)^2
  - (y-y')^2

## 데이터 세트에서 L2 손실 정의하기  
<img src="https://user-images.githubusercontent.com/32586985/68349781-a6227700-0141-11ea-8091-d75650da4362.PNG">
<img src="https://user-images.githubusercontent.com/32586985/68349917-18935700-0142-11ea-9562-d43072bbc31e.PNG">




## 선형 회귀   
- 선형 회귀의 예시 1분당 귀뚜라미가 우는 횟수와 온도에 관한 데이터
### 그림 1. 1분당 우는 횟수 및 섭씨온도  
<img src="https://user-images.githubusercontent.com/32586985/68350091-9e170700-0142-11ea-9628-4cc3f38cfe1e.PNG"> 

- 우는 횟수가 증가할수록 온도가 올라가는 것 확인/ 이 관계를 근사치로 하는 하나의 직선을 그릴 수 있음
### 그림 2. 선형 관계
<img src="https://user-images.githubusercontent.com/32586985/68350242-14b40480-0143-11ea-9e78-58cb9b2421ca.PNG">

- 온도 데이터와 우는 소리 데이터의 관계를 명확히 보여줌  
- 대수학을 적용해 관계를 알 수 있음  
<img src="https://user-images.githubusercontent.com/32586985/68350652-627d3c80-0144-11ea-9cec-8bef7a70f886.PNG">

        - y는 섭씨온도, 예측하려는 값
        - m은 선의 기울기
        - x는 1분당 우는 횟수, 입력 특성 값
        - b는 y절편
- 머신러닝 관습에 따라 모델의 방정식을 약간 다르게 작성 가능
<img src="https://user-images.githubusercontent.com/32586985/68350718-97898f00-0144-11ea-8003-c88c049b3993.PNG">
     
        - y'는 예측된 라벨(얻고자 하는 출력)
        - b 는 편향(y절편)임/일부 머신러닝 자료에서는 w0라고도 함
        - w1은 특성 1의 가중치임/가중치는 위에서 m으로 표현된 기울기와 같은 개념임
        - x1은 특성(알려진 입력)임
- 새로운 분당 우는 횟수x1에서 온도y'를 추론(예측)하려면 x1 값을 이 모델에 삽입하기만 하면 됨 
- 아래첨자(예:w1,x1)는 여러 특성에 의존하는 좀 더 정교한 모델을 예시함
- 세 가지 특성에 의존하는 모델은 다음과 같은 방정식을 사용함 
<img src="https://user-images.githubusercontent.com/32586985/68350767-c869c400-0144-11ea-81d0-2ade0acff560.PNG">




## 학습 및 손실  
- 모델을 학습 시킨다는 것은 라벨이 있는 데이터로부터 올바른 가중치와 편향값을 학습하는것
- 지도 학습에서 머신러닝 알고리즘은 다양한 예를 검토하고 손실을 최소화 하는 모델을 찾아봄으로써 모델을 만들어냄/이 과정은 경험적 위험 최소화라고 함  
- 손실은 잘못된 예측에 대한 벌점임/한 가지 예에서 모델의 예측이 얼마나 잘못되었는지를 나타내는 수임 
- 모델의 예측이 완벽하면 손실은 0이고 그렇지 않으면 손실은 그보다 커짐 
- 모델 학습의 목표는 모든 예에서 평균적으로 작은 손실을 갖는 가중치와 편향의 집합을 찾는 것임

  
### 그림 3. 왼쪽 모델은 손실이 크고 오른쪽 모델은 손실이 작음
#### 빨간색 화살표는 손실을 나타냄/파란색 직선은 예측을 나타냄
<img src="https://user-images.githubusercontent.com/32586985/68351138-e2f06d00-0145-11ea-8cb8-919180bfa815.PNG">

- 왼쪽 그래프에서 빨간색 화살표는 오른쪽 그래프의 화살표보다 훨씬 더 김  
- 오른쪽 그래프의 파란색 직선은 왼쪽 그래프의 파란색 직선보다 훨씬 더 예측을 잘 하는 모델임

## 제곱 손실:잘 알려진 손실 함수  
- 여기에서 살펴볼 선형 회귀 모델에서는 제곱 손실(또는 L2 손실)이라는 손실 함수를 사용함
- 데이터 하나의 제곱 손실은 다음과 같이 나타남 
```octave
   = the square of the difference between the label and the prediction 
   = (observation - prediction(x))^2
   = (y - y')^2
```
- 평균 제곱 오차(MSE)는 예시당 평균 제곱 손실임
- MSE를 계산하려면 개별 예의 모든 제곱 손실을 합한 다음 예의 수로 나눔  
<img src="https://user-images.githubusercontent.com/32586985/68351968-5b582d80-0148-11ea-8510-be4355242026.PNG">

    - (x,y)는 예이며, 다음과 같음
       - x는 모델이 예측하는 데 사용하는 특성 집합(예:온도,나이,짝짓기 성공률)임
       - y는 예의 라벨(예:분당 우는 소리)임
    - prediction(x)은 특성 집합x과 결합된 가중치 및 편향의 함수임  
    - D는 (x,y)쌍과 같이 여러 라벨이 있는 예가 포함된 데이터 세트임 
    - N은 D에 포함된 예의 수임  
- MSE는 머신러닝에서 흔히 사용되지만, 모든 상황에서 최선인 유일한 손실 함수는 아님      
